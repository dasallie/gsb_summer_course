{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference paper:\n",
    "# Duarte 2018, Gradient-Based Structural Estimation (working paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow_probability as tfp\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminal date\n",
    "T = 9\n",
    "\n",
    "# Network design and optization hyperparameters\n",
    "batch_size = 5000\n",
    "activation = tf.nn.relu\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "optimizer_moment_network = tf.keras.optimizers.Adam()\n",
    "\n",
    "state_size = 3\n",
    "\n",
    "\n",
    "# function that creates a network\n",
    "def net():\n",
    "    model = Sequential([Dense(32, activation, input_shape=(state_size,)),\n",
    "                        Dense(32, activation),\n",
    "                        Dense(1, 'sigmoid')])\n",
    "    return model\n",
    "\n",
    "\n",
    "n = [net() for _ in range(T)]\n",
    "Θ = [n[t].weights for t in range(T)]\n",
    "Θ = [item for sublist in Θ for item in sublist]\n",
    "\n",
    "# moment network\n",
    "g = Sequential([Dense(32, 'elu', input_shape=(1,)),\n",
    "                Dense(32, 'elu'),\n",
    "                Dense(1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Economic Model ------------------------------------------------------\n",
    "\n",
    "# Model parameters\n",
    "σ_ε = 0.02058\n",
    "λ_ε = 0.99\n",
    "β = .97\n",
    "\n",
    "# Prices\n",
    "r = 0.07\n",
    "w = 5\n",
    "\n",
    "μx = 2.\n",
    "σx = 1.\n",
    "\n",
    "μe = 0.\n",
    "σe = .14\n",
    "\n",
    "μγ = 3.\n",
    "σγ = 1.\n",
    "\n",
    "def u(C, γ):\n",
    "    return C**(1 - γ) / (1 - γ)\n",
    "\n",
    "\n",
    "def normalize(x, e, γ):\n",
    "    x = (x - μx) / σx\n",
    "    e = (e - μe) / σe\n",
    "    γ = (γ - μγ) / σγ\n",
    "\n",
    "    X = tf.concat([x, e, γ], 1)\n",
    "    return X\n",
    "\n",
    "\n",
    "def simulate():\n",
    "    x0 = tf.random.uniform([batch_size, 1], minval=.01, maxval=4)\n",
    "    e0 = tf.random.uniform([batch_size, 1], minval=-.25, maxval=.25)\n",
    "    γ = tf.random.uniform([batch_size, 1], minval=1.2, maxval=5)\n",
    "\n",
    "    # Normal shock at t=0\n",
    "    def ε():\n",
    "        return tf.random.normal(shape=[batch_size, 1])\n",
    "\n",
    "    # Organize variables and shocks in dictionaries\n",
    "    x = {0: x0}\n",
    "    e = {0: e0}\n",
    "    s = {}\n",
    "    y = {}\n",
    "    C = {}\n",
    "\n",
    "    for t in range(T):\n",
    "        # The inputs of the network are wealth and productivity at t\n",
    "        X = normalize(x[t], e[t], γ)\n",
    "        s[t] = n[t](X)\n",
    "\n",
    "        # Disposable income\n",
    "        y[t] = (1 + r) * x[t] + tf.exp(e[t]) * w\n",
    "\n",
    "        # Consumption\n",
    "        C[t] = (1 - s[t]) * y[t]\n",
    "\n",
    "        # Next states\n",
    "        e[t + 1] = λ_ε * e[t] + σ_ε * ε()\n",
    "        x[t + 1] = s[t] * y[t]\n",
    "\n",
    "    # Terminal values\n",
    "    C[T] = (1 + r) * x[T] + tf.exp(e[T]) * w\n",
    "\n",
    "    # Moment\n",
    "    moment = C[T]\n",
    "\n",
    "    V = sum([β**t * u(C[t], γ) for t in range(T + 1)])\n",
    "    return V, [x, e, γ], moment\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def training_step():\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        V, [x, e, γ], moment = simulate()\n",
    "        objective = -tf.reduce_mean(V)\n",
    "\n",
    "        predicted = g(γ - μγ)\n",
    "        loss = tf.reduce_mean((predicted - moment)**2)\n",
    "\n",
    "    # optimization    EV, results = training_step()\n",
    "    grads = tape.gradient(objective, Θ)\n",
    "    optimizer.apply_gradients(zip(grads, Θ))\n",
    "\n",
    "    # Construct the moment network\n",
    "    ΘM = g.weights\n",
    "    grads = tape.gradient(loss, ΘM)\n",
    "    optimizer_moment_network.apply_gradients(zip(grads, ΘM))\n",
    "    return -objective, [x, e, γ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(γ):\n",
    "    target = 5.87\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(γ)\n",
    "        L = (g(γ - μγ) - target)**2\n",
    "        dL = tape.gradient(L, γ)\n",
    "    return L[0, 0], dL\n",
    "\n",
    "\n",
    "start = tf.constant([3.])\n",
    "\n",
    "\n",
    "def estimate(start):\n",
    "    optim_results = tfp.optimizer.bfgs_minimize(\n",
    "        loss_function, initial_position=start, max_iterations=5)\n",
    "    β0 = optim_results.position\n",
    "    return β0.numpy()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "γ_buffer = []\n",
    "\n",
    "n_iterations = 10000\n",
    "for iteration in range(n_iterations):\n",
    "    EV, results = training_step()\n",
    "    if iteration % 1000 == 0:\n",
    "        print(str((iteration) / n_iterations * 100) + '%')\n",
    "\n",
    "    if iteration % 50 == 0:\n",
    "        start = tf.random.uniform([1], 1.2, 5.)\n",
    "        γ_star = estimate(start)\n",
    "        γ_buffer.append(γ_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(results, color='blue'):\n",
    "\n",
    "    def plot_one(t, color):\n",
    "        xt = results[0][t]\n",
    "        et = tf.zeros_like(xt)\n",
    "        γ = 2. * tf.ones_like(xt)\n",
    "\n",
    "        X = normalize(xt, et, γ)\n",
    "        s = n[t](X)\n",
    "\n",
    "        # Disposable income\n",
    "        y = (1 + r) * xt + tf.exp(et) * w\n",
    "\n",
    "        # Consumption\n",
    "        C = (1 - s) * y\n",
    "\n",
    "        plt.scatter(xt, C, s=1, color=color)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plot_one(t=0, color='b')\n",
    "    plot_one(t=3, color='r')\n",
    "    plot_one(t=6, color='k')\n",
    "\n",
    "    plt.plot(xgrid, C[0, :, 10])\n",
    "    plt.plot(xgrid, C[3, :, 10])\n",
    "    plt.plot(xgrid, C[6, :, 10])\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    γ = tf.reshape(tf.linspace(1.2, 5., 1000), [-1, 1])\n",
    "    m_hat = moment_network(γ - μγ)\n",
    "\n",
    "    γ_ = [1.2, 1.5, 2, 2.5, 3, 3.5, 4.5]\n",
    "    m_ = [6.22, 6.05, 5.87, 5.77, 5.70, 5.65, 5.59]\n",
    "    plt.plot(γ, m_hat, color=color)\n",
    "    plt.scatter(γ_, m_, color='r')\n",
    "    plt.show()\n",
    "    plt.pause(1e-6)\n",
    "\n",
    "    plt.show()\n",
    "    plt.pause(1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "γ_ = np.array(γ_buffer[-50:])\n",
    "γ_ = γ_[γ_ < 5]\n",
    "γ_ = γ_[γ_ > 1]\n",
    "plt.hist(γ_)\n",
    "\n",
    "γ_.mean(), γ_.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_γ(shape):\n",
    "    out = tf.random.normal(shape, γ_.mean(), γ_.std())\n",
    "    out = tf.maximum(out, 1.2)\n",
    "    out = tf.minimum(out, 5)\n",
    "    return out\n",
    "\n",
    "\n",
    "# If you want to reduce the standard deviations, you can\n",
    "# reduce the learning rates\n",
    "optimizer.lr.assign(1e-5)\n",
    "optimizer_moment_network.lr.assign(1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate():\n",
    "    x0 = tf.random.uniform([batch_size, 1], minval=.01, maxval=4)\n",
    "    e0 = tf.random.uniform([batch_size, 1], minval=-.25, maxval=.25)\n",
    "    γ = sample_γ([batch_size, 1])\n",
    "\n",
    "    # Normal shock at t=0\n",
    "    def ε():\n",
    "        return tf.random.normal(shape=[batch_size, 1])\n",
    "\n",
    "    # Organize variables and shocks in dictionaries\n",
    "    x = {0: x0}\n",
    "    e = {0: e0}\n",
    "    s = {}\n",
    "    y = {}\n",
    "    C = {}\n",
    "\n",
    "    for t in range(T):\n",
    "        # The inputs of the network are wealth and productivity at t\n",
    "        X = normalize(x[t], e[t], γ)\n",
    "        s[t] = n[t](X)\n",
    "\n",
    "        # Disposable income\n",
    "        y[t] = (1 + r) * x[t] + tf.exp(e[t]) * w\n",
    "\n",
    "        # Consumption\n",
    "        C[t] = (1 - s[t]) * y[t]\n",
    "\n",
    "        # Next states\n",
    "        e[t + 1] = λ_ε * e[t] + σ_ε * ε()\n",
    "        x[t + 1] = s[t] * y[t]\n",
    "\n",
    "    # Terminal values\n",
    "    C[T] = (1 + r) * x[T] + tf.exp(e[T]) * w\n",
    "\n",
    "    # Moment\n",
    "    moment = C[T]\n",
    "\n",
    "    V = sum([β**t * u(C[t], γ) for t in range(T + 1)])\n",
    "    return V, [x, e, γ], moment\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def training_step():\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        V, [x, e, γ], moment = simulate()\n",
    "        objective = -tf.reduce_mean(V)\n",
    "\n",
    "        predicted = g(γ - μγ)\n",
    "        loss = tf.reduce_mean((predicted - moment)**2)\n",
    "\n",
    "    # optimization\n",
    "    grads = tape.gradient(objective, Θ)\n",
    "    optimizer.apply_gradients(zip(grads, Θ))\n",
    "\n",
    "    # Construct the moment network\n",
    "    ΘM = g.weights\n",
    "    grads = tape.gradient(loss, ΘM)\n",
    "    optimizer_moment_network.apply_gradients(zip(grads, ΘM))\n",
    "    return -objective, [x, e, γ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "γ_buffer = []\n",
    "n_iterations = 10000\n",
    "for iteration in range(n_iterations):\n",
    "    EV, results = training_step()\n",
    "    if iteration % 1000 == 0:\n",
    "        print(str((iteration) / n_iterations * 100) + '%')\n",
    "\n",
    "    if iteration % 50 == 0:\n",
    "        start = sample_γ(shape=[1])\n",
    "        γ_star = estimate(start)\n",
    "        γ_buffer.append(γ_star)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "γ_ = np.array(γ_buffer[-30:])\n",
    "γ_ = γ_[γ_ < 5]\n",
    "γ_ = γ_[γ_ > 1]\n",
    "plt.hist(γ_)\n",
    "\n",
    "print(γ_.mean(), γ_.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
